{"ast":null,"code":"var _jsxFileName = \"/Users/abhinavprasad/Desktop/ai-face-detection/src/App.js\",\n    _s = $RefreshSig$();\n\nimport { useRef, useEffect, useState } from 'react';\nimport './App.css';\nimport * as faceapi from \"face-api.js\";\nimport { FaceExpressions } from 'face-api.js';\nimport express from 'express';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  // const app = express();\n  let number = 0;\n  let client_id = '42637a421e564dffacf392cd0fef3df6';\n  let client_Secret = '9fba64c6a89d45539af2fe64ac3fc37c';\n  const [accessToken, setaccessToken] = useState(\"\");\n  const videoRef = useRef();\n  const canvasRef = useRef(); // app.get(\"/authorize\", (req,res) => {\n  //   var auth_params = new URLSearchParams({\n  //     response_type : \"code\",\n  //     client_id : \"42637a421e564dffacf392cd0fef3df6\",\n  //     scope : \"\",\n  //     redirect_uri : \"http://localhost:3001/callback\",\n  //   })\n  //   res.redirect(\"https://accounts.spotify.com/authorize?\" + auth_params.toString());\n  // })\n  // app.get(\"/callback\", (req,res) => {\n  //   const code = req.query.code;\n  //   console.log(code);\n  // })\n  // useEffect(() => {\n  //   var auth_params = {\n  //     method: 'POST',\n  //     headers: {\n  //       'Content-Type' : 'application/x-www-form-urlencoded'\n  //     },\n  //     body: 'grant_type=client_credentials&client_id=' + client_id + '&client_secret=' + client_Secret\n  //   }\n  //   fetch('https:/accounts.spotify.com/api/token', auth_params)\n  //   .then(result => result.json())\n  //   .then(data => console.log(data))\n  //   .then(data => setaccessToken(data.access_token))\n  // },[])\n\n  useEffect(() => {\n    startVideo();\n    videoRef && loadModels();\n  }, []);\n\n  const loadModels = () => {\n    Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri('/models'), faceapi.nets.faceLandmark68Net.loadFromUri('/models'), faceapi.nets.faceRecognitionNet.loadFromUri('/models'), faceapi.nets.faceExpressionNet.loadFromUri('/models')]).then(() => {\n      faceDetection();\n    });\n  };\n\n  const startVideo = () => {\n    navigator.mediaDevices.getUserMedia({\n      video: true\n    }).then(currentStream => {\n      videoRef.current.srcObject = currentStream;\n    }).catch(err => {\n      console.error(err);\n    });\n  };\n\n  const faceDetection = async () => {\n    setInterval(async () => {\n      if (number == 1) {\n        return;\n      }\n\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      let emotions_displayed = detections[0].expressions;\n\n      if (emotions_displayed != undefined) {\n        number++;\n      }\n\n      let max_emotion = 0;\n      let final_emotion = \"\";\n\n      for (const [key, value] of Object.entries(emotions_displayed)) {\n        if (value > max_emotion) {\n          max_emotion = value;\n          final_emotion = key;\n        }\n      }\n\n      console.log(final_emotion + ':' + max_emotion);\n      canvasRef.current.innerHtml = faceapi.createCanvasFromMedia(videoRef.current);\n      faceapi.matchDimensions(canvasRef.current, {\n        width: 940,\n        height: 650\n      });\n      const resized = faceapi.resizeResults(detections, {\n        width: 940,\n        height: 650\n      });\n      faceapi.draw.drawDetections(canvasRef.current, resized);\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, resized);\n      faceapi.draw.drawFaceExpressions(canvasRef.current, resized);\n      let number_of_playlists = 5;\n      let selected_playlist = Math.floor(Math.random() * number_of_playlists);\n    }, 1000);\n  };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"app\",\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \" AI FACE DETECTION\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 131,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"  \"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 132,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"app__video\",\n      children: /*#__PURE__*/_jsxDEV(\"video\", {\n        crossOrigin: \"anonymous\",\n        ref: videoRef,\n        autoPlay: true\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 134,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 133,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      width: \"940\",\n      height: \"650\",\n      className: \"app__canvas\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 136,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 130,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"E0hWs6tNYPX/MgiBqLoQOtXiSOE=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/abhinavprasad/Desktop/ai-face-detection/src/App.js"],"names":["useRef","useEffect","useState","faceapi","FaceExpressions","express","App","number","client_id","client_Secret","accessToken","setaccessToken","videoRef","canvasRef","startVideo","loadModels","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","faceDetection","navigator","mediaDevices","getUserMedia","video","currentStream","current","srcObject","catch","err","console","error","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","emotions_displayed","expressions","undefined","max_emotion","final_emotion","key","value","Object","entries","log","innerHtml","createCanvasFromMedia","matchDimensions","width","height","resized","resizeResults","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions","number_of_playlists","selected_playlist","Math","floor","random"],"mappings":";;;AAAA,SAASA,MAAT,EAAiBC,SAAjB,EAA4BC,QAA5B,QAA4C,OAA5C;AACA,OAAO,WAAP;AACA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;AACA,SAASC,eAAT,QAAgC,aAAhC;AACA,OAAOC,OAAP,MAAoB,SAApB;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AAGb;AAEA,MAAIC,MAAM,GAAG,CAAb;AACA,MAAIC,SAAS,GAAG,kCAAhB;AACA,MAAIC,aAAa,GAAG,kCAApB;AACA,QAAM,CAACC,WAAD,EAAcC,cAAd,IAAgCT,QAAQ,CAAC,EAAD,CAA9C;AAEA,QAAMU,QAAQ,GAAGZ,MAAM,EAAvB;AACA,QAAMa,SAAS,GAAGb,MAAM,EAAxB,CAXa,CAab;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAIAC,EAAAA,SAAS,CAAC,MAAM;AACda,IAAAA,UAAU;AAEVF,IAAAA,QAAQ,IAAIG,UAAU,EAAtB;AAED,GALQ,EAKN,EALM,CAAT;;AAOE,QAAMA,UAAU,GAAG,MAAM;AACvBC,IAAAA,OAAO,CAACC,GAAR,CAAY,CACVd,OAAO,CAACe,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0C,SAA1C,CADU,EAEVjB,OAAO,CAACe,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2C,SAA3C,CAFU,EAGVjB,OAAO,CAACe,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4C,SAA5C,CAHU,EAIVjB,OAAO,CAACe,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2C,SAA3C,CAJU,CAAZ,EAKGI,IALH,CAKQ,MAAM;AACZC,MAAAA,aAAa;AACd,KAPD;AAQD,GATD;;AAWF,QAAMX,UAAU,GAAG,MAAM;AACvBY,IAAAA,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoC;AAAEC,MAAAA,KAAK,EAAE;AAAT,KAApC,EACGL,IADH,CACSM,aAAD,IAAmB;AACvBlB,MAAAA,QAAQ,CAACmB,OAAT,CAAiBC,SAAjB,GAA6BF,aAA7B;AACD,KAHH,EAIGG,KAJH,CAIUC,GAAD,IAAS;AACdC,MAAAA,OAAO,CAACC,KAAR,CAAcF,GAAd;AACD,KANH;AAOD,GARD;;AAUA,QAAMT,aAAa,GAAG,YAAY;AAChCY,IAAAA,WAAW,CAAC,YAAW;AACrB,UAAI9B,MAAM,IAAE,CAAZ,EACA;AACE;AACD;;AACD,YAAM+B,UAAU,GAAG,MAAMnC,OAAO,CAACoC,cAAR,CAAuB3B,QAAQ,CAACmB,OAAhC,EAAyC,IAAI5B,OAAO,CAACqC,uBAAZ,EAAzC,EAAgFC,iBAAhF,GAAoGC,mBAApG,EAAzB;AACA,UAAIC,kBAAkB,GAAGL,UAAU,CAAC,CAAD,CAAV,CAAcM,WAAvC;;AACA,UAAID,kBAAkB,IAAIE,SAA1B,EACA;AACEtC,QAAAA,MAAM;AACP;;AACD,UAAIuC,WAAW,GAAG,CAAlB;AACA,UAAIC,aAAa,GAAG,EAApB;;AACA,WAAK,MAAM,CAACC,GAAD,EAAKC,KAAL,CAAX,IAA0BC,MAAM,CAACC,OAAP,CAAeR,kBAAf,CAA1B,EACA;AACE,YAAIM,KAAK,GAAGH,WAAZ,EACA;AACEA,UAAAA,WAAW,GAAGG,KAAd;AACAF,UAAAA,aAAa,GAAGC,GAAhB;AACD;AACF;;AACDb,MAAAA,OAAO,CAACiB,GAAR,CAAYL,aAAa,GAAG,GAAhB,GAAsBD,WAAlC;AAEAjC,MAAAA,SAAS,CAACkB,OAAV,CAAkBsB,SAAlB,GAA8BlD,OAAO,CAACmD,qBAAR,CAA8B1C,QAAQ,CAACmB,OAAvC,CAA9B;AACA5B,MAAAA,OAAO,CAACoD,eAAR,CAAwB1C,SAAS,CAACkB,OAAlC,EAA2C;AACzCyB,QAAAA,KAAK,EAAE,GADkC;AAEzCC,QAAAA,MAAM,EAAE;AAFiC,OAA3C;AAKA,YAAMC,OAAO,GAAGvD,OAAO,CAACwD,aAAR,CAAsBrB,UAAtB,EAAkC;AAChDkB,QAAAA,KAAK,EAAE,GADyC;AAEhDC,QAAAA,MAAM,EAAE;AAFwC,OAAlC,CAAhB;AAKAtD,MAAAA,OAAO,CAACyD,IAAR,CAAaC,cAAb,CAA4BhD,SAAS,CAACkB,OAAtC,EAA+C2B,OAA/C;AACAvD,MAAAA,OAAO,CAACyD,IAAR,CAAaE,iBAAb,CAA+BjD,SAAS,CAACkB,OAAzC,EAAkD2B,OAAlD;AACAvD,MAAAA,OAAO,CAACyD,IAAR,CAAaG,mBAAb,CAAiClD,SAAS,CAACkB,OAA3C,EAAoD2B,OAApD;AAEA,UAAIM,mBAAmB,GAAG,CAA1B;AACA,UAAIC,iBAAiB,GAAGC,IAAI,CAACC,KAAL,CAAWD,IAAI,CAACE,MAAL,KAAgBJ,mBAA3B,CAAxB;AAED,KAzCU,EAyCR,IAzCQ,CAAX;AA0CD,GA3CD;;AA6CA,sBACE;AAAM,IAAA,SAAS,EAAC,KAAhB;AAAA,4BACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF,eAGE;AAAK,MAAA,SAAS,EAAC,YAAf;AAAA,6BACE;AAAO,QAAA,WAAW,EAAC,WAAnB;AAA+B,QAAA,GAAG,EAAEpD,QAApC;AAA8C,QAAA,QAAQ;AAAtD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,YAHF,eAMI;AAAQ,MAAA,GAAG,EAAEC,SAAb;AAAwB,MAAA,KAAK,EAAC,KAA9B;AAAoC,MAAA,MAAM,EAAC,KAA3C;AAAiD,MAAA,SAAS,EAAC;AAA3D;AAAA;AAAA;AAAA;AAAA,YANJ;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAWD;;GArIQP,G;;KAAAA,G;AAuIT,eAAeA,GAAf","sourcesContent":["import { useRef, useEffect, useState } from 'react';\nimport './App.css';\nimport * as faceapi from \"face-api.js\";\nimport { FaceExpressions } from 'face-api.js';\nimport express from 'express';\n\nfunction App() {\n\n  \n  // const app = express();\n\n  let number = 0;\n  let client_id = '42637a421e564dffacf392cd0fef3df6';\n  let client_Secret = '9fba64c6a89d45539af2fe64ac3fc37c';\n  const [accessToken, setaccessToken] = useState(\"\")\n\n  const videoRef = useRef();\n  const canvasRef = useRef();\n\n  // app.get(\"/authorize\", (req,res) => {\n\n  //   var auth_params = new URLSearchParams({\n  //     response_type : \"code\",\n  //     client_id : \"42637a421e564dffacf392cd0fef3df6\",\n  //     scope : \"\",\n  //     redirect_uri : \"http://localhost:3001/callback\",\n  //   })\n\n  //   res.redirect(\"https://accounts.spotify.com/authorize?\" + auth_params.toString());\n  // })\n\n  // app.get(\"/callback\", (req,res) => {\n\n  //   const code = req.query.code;\n  //   console.log(code);\n  // })\n\n  // useEffect(() => {\n    \n  //   var auth_params = {\n  //     method: 'POST',\n  //     headers: {\n  //       'Content-Type' : 'application/x-www-form-urlencoded'\n  //     },\n  //     body: 'grant_type=client_credentials&client_id=' + client_id + '&client_secret=' + client_Secret\n  //   }\n  //   fetch('https:/accounts.spotify.com/api/token', auth_params)\n  //   .then(result => result.json())\n  //   .then(data => console.log(data))\n  //   .then(data => setaccessToken(data.access_token))\n\n  // },[])\n\n  \n\n  useEffect(() => {\n    startVideo();\n\n    videoRef && loadModels();\n\n  }, []);\n  \n    const loadModels = () => {\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri('/models'),\n        faceapi.nets.faceLandmark68Net.loadFromUri('/models'),\n        faceapi.nets.faceRecognitionNet.loadFromUri('/models'),\n        faceapi.nets.faceExpressionNet.loadFromUri('/models'),\n      ]).then(() => {\n        faceDetection();\n      })\n    };\n\n  const startVideo = () => {\n    navigator.mediaDevices.getUserMedia({ video: true })\n      .then((currentStream) => {\n        videoRef.current.srcObject = currentStream;\n      })\n      .catch((err) => {\n        console.error(err)\n      });\n  }\n\n  const faceDetection = async () => {\n    setInterval(async() => {\n      if (number==1)\n      {\n        return\n      }\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      let emotions_displayed = detections[0].expressions;\n      if (emotions_displayed != undefined)\n      {\n        number++;\n      }\n      let max_emotion = 0\n      let final_emotion = \"\"\n      for (const [key,value] of Object.entries(emotions_displayed))\n      {\n        if (value > max_emotion)\n        {\n          max_emotion = value\n          final_emotion = key\n        }\n      }\n      console.log(final_emotion + ':' + max_emotion)\n  \n      canvasRef.current.innerHtml = faceapi.createCanvasFromMedia(videoRef.current);\n      faceapi.matchDimensions(canvasRef.current, {\n        width: 940,\n        height: 650,\n      })\n\n      const resized = faceapi.resizeResults(detections, {\n        width: 940,\n        height: 650,\n      });\n\n      faceapi.draw.drawDetections(canvasRef.current, resized)\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, resized)\n      faceapi.draw.drawFaceExpressions(canvasRef.current, resized)\n\n      let number_of_playlists = 5\n      let selected_playlist = Math.floor(Math.random() * number_of_playlists)\n\n    }, 1000)\n  }\n\n  return (\n    <div  className=\"app\">\n      <h1> AI FACE DETECTION</h1>\n      <h1>  </h1>\n      <div className='app__video'>\n        <video crossOrigin='anonymous' ref={videoRef} autoPlay ></video>\n      </div>\n        <canvas ref={canvasRef} width=\"940\" height=\"650\" className='app__canvas' />\n      \n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}