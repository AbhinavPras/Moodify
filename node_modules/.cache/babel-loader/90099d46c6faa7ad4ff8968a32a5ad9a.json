{"ast":null,"code":"var _jsxFileName = \"/Users/abhinavprasad/Desktop/ai-face-detection/src/App.js\",\n    _s = $RefreshSig$();\n\nimport { useRef, useEffect } from 'react';\nimport './App.css';\nimport * as faceapi from \"face-api.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  const videoRef = useRef();\n  const canvasRef = useRef();\n  useEffect(() => {\n    startVideo();\n    videoRef && loadModels();\n  }, []);\n\n  const loadModels = () => {\n    Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri('/models'), faceapi.nets.faceLandmark68Net.loadFromUri('/models'), faceapi.nets.faceRecognitionNet.loadFromUri('/models'), faceapi.nets.faceExpressionNet.loadFromUri('/models')]).then(() => {\n      faceDetection();\n    });\n  };\n\n  const startVideo = () => {\n    navigator.mediaDevices.getUserMedia({\n      video: true\n    }).then(currentStream => {\n      videoRef.current.srcObject = currentStream;\n    }).catch(err => {\n      console.error(err);\n    });\n  };\n\n  const faceDetection = async () => {\n    setInterval(async () => {\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      canvasRef.current.innerHtml = faceapi.createCanvasFromMedia(videoRef.current);\n      faceapi.matchDimensions(canvasRef.current, {\n        width: 940,\n        height: 650\n      });\n      const resized = faceapi.resizeResults(detections, {\n        width: 940,\n        height: 650\n      });\n      faceapi.draw.drawDetections(canvasRef.current, resized);\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, resized);\n      faceapi.draw.drawFaceExpressions(canvasRef.current, resized);\n    }, 1000);\n  };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"app\",\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \" AI FACE DETECTION\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 62,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"app__video\",\n      children: /*#__PURE__*/_jsxDEV(\"video\", {\n        crossOrigin: \"anonymous\",\n        ref: videoRef,\n        autoPlay: true\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 64,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 63,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      width: \"940\",\n      height: \"650\",\n      className: \"app__canvas\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 66,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 61,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"0gwqVvoOV2or9Ql4L8GH2BGn3hc=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/abhinavprasad/Desktop/ai-face-detection/src/App.js"],"names":["useRef","useEffect","faceapi","App","videoRef","canvasRef","startVideo","loadModels","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","faceDetection","navigator","mediaDevices","getUserMedia","video","currentStream","current","srcObject","catch","err","console","error","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","innerHtml","createCanvasFromMedia","matchDimensions","width","height","resized","resizeResults","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions"],"mappings":";;;AAAA,SAASA,MAAT,EAAiBC,SAAjB,QAAkC,OAAlC;AACA,OAAO,WAAP;AACA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AACb,QAAMC,QAAQ,GAAGJ,MAAM,EAAvB;AACA,QAAMK,SAAS,GAAGL,MAAM,EAAxB;AAEAC,EAAAA,SAAS,CAAC,MAAM;AACdK,IAAAA,UAAU;AAEVF,IAAAA,QAAQ,IAAIG,UAAU,EAAtB;AAED,GALQ,EAKN,EALM,CAAT;;AAOE,QAAMA,UAAU,GAAG,MAAM;AACvBC,IAAAA,OAAO,CAACC,GAAR,CAAY,CACVP,OAAO,CAACQ,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0C,SAA1C,CADU,EAEVV,OAAO,CAACQ,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2C,SAA3C,CAFU,EAGVV,OAAO,CAACQ,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4C,SAA5C,CAHU,EAIVV,OAAO,CAACQ,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2C,SAA3C,CAJU,CAAZ,EAKGI,IALH,CAKQ,MAAM;AACZC,MAAAA,aAAa;AACd,KAPD;AAQD,GATD;;AAWF,QAAMX,UAAU,GAAG,MAAM;AACvBY,IAAAA,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoC;AAAEC,MAAAA,KAAK,EAAE;AAAT,KAApC,EACGL,IADH,CACSM,aAAD,IAAmB;AACvBlB,MAAAA,QAAQ,CAACmB,OAAT,CAAiBC,SAAjB,GAA6BF,aAA7B;AACD,KAHH,EAIGG,KAJH,CAIUC,GAAD,IAAS;AACdC,MAAAA,OAAO,CAACC,KAAR,CAAcF,GAAd;AACD,KANH;AAOD,GARD;;AAUA,QAAMT,aAAa,GAAG,YAAY;AAChCY,IAAAA,WAAW,CAAC,YAAW;AACrB,YAAMC,UAAU,GAAG,MAAM5B,OAAO,CAAC6B,cAAR,CAAuB3B,QAAQ,CAACmB,OAAhC,EAAyC,IAAIrB,OAAO,CAAC8B,uBAAZ,EAAzC,EAAgFC,iBAAhF,GAAoGC,mBAApG,EAAzB;AACA7B,MAAAA,SAAS,CAACkB,OAAV,CAAkBY,SAAlB,GAA8BjC,OAAO,CAACkC,qBAAR,CAA8BhC,QAAQ,CAACmB,OAAvC,CAA9B;AACArB,MAAAA,OAAO,CAACmC,eAAR,CAAwBhC,SAAS,CAACkB,OAAlC,EAA2C;AACzCe,QAAAA,KAAK,EAAE,GADkC;AAEzCC,QAAAA,MAAM,EAAE;AAFiC,OAA3C;AAKA,YAAMC,OAAO,GAAGtC,OAAO,CAACuC,aAAR,CAAsBX,UAAtB,EAAkC;AAChDQ,QAAAA,KAAK,EAAE,GADyC;AAEhDC,QAAAA,MAAM,EAAE;AAFwC,OAAlC,CAAhB;AAKArC,MAAAA,OAAO,CAACwC,IAAR,CAAaC,cAAb,CAA4BtC,SAAS,CAACkB,OAAtC,EAA+CiB,OAA/C;AACAtC,MAAAA,OAAO,CAACwC,IAAR,CAAaE,iBAAb,CAA+BvC,SAAS,CAACkB,OAAzC,EAAkDiB,OAAlD;AACAtC,MAAAA,OAAO,CAACwC,IAAR,CAAaG,mBAAb,CAAiCxC,SAAS,CAACkB,OAA3C,EAAoDiB,OAApD;AAED,KAjBU,EAiBR,IAjBQ,CAAX;AAkBD,GAnBD;;AAuBA,sBACE;AAAM,IAAA,SAAS,EAAC,KAAhB;AAAA,4BACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAK,MAAA,SAAS,EAAC,YAAf;AAAA,6BACE;AAAO,QAAA,WAAW,EAAC,WAAnB;AAA+B,QAAA,GAAG,EAAEpC,QAApC;AAA8C,QAAA,QAAQ;AAAtD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,YAFF,eAKI;AAAQ,MAAA,GAAG,EAAEC,SAAb;AAAwB,MAAA,KAAK,EAAC,KAA9B;AAAoC,MAAA,MAAM,EAAC,KAA3C;AAAiD,MAAA,SAAS,EAAC;AAA3D;AAAA;AAAA;AAAA;AAAA,YALJ;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAUD;;GAjEQF,G;;KAAAA,G;AAmET,eAAeA,GAAf","sourcesContent":["import { useRef, useEffect } from 'react';\nimport './App.css';\nimport * as faceapi from \"face-api.js\";\n\nfunction App() {\n  const videoRef = useRef();\n  const canvasRef = useRef();\n\n  useEffect(() => {\n    startVideo();\n\n    videoRef && loadModels();\n\n  }, []);\n  \n    const loadModels = () => {\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri('/models'),\n        faceapi.nets.faceLandmark68Net.loadFromUri('/models'),\n        faceapi.nets.faceRecognitionNet.loadFromUri('/models'),\n        faceapi.nets.faceExpressionNet.loadFromUri('/models'),\n      ]).then(() => {\n        faceDetection();\n      })\n    };\n\n  const startVideo = () => {\n    navigator.mediaDevices.getUserMedia({ video: true })\n      .then((currentStream) => {\n        videoRef.current.srcObject = currentStream;\n      })\n      .catch((err) => {\n        console.error(err)\n      });\n  }\n\n  const faceDetection = async () => {\n    setInterval(async() => {\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      canvasRef.current.innerHtml = faceapi.createCanvasFromMedia(videoRef.current);\n      faceapi.matchDimensions(canvasRef.current, {\n        width: 940,\n        height: 650,\n      })\n\n      const resized = faceapi.resizeResults(detections, {\n        width: 940,\n        height: 650,\n      });\n\n      faceapi.draw.drawDetections(canvasRef.current, resized)\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, resized)\n      faceapi.draw.drawFaceExpressions(canvasRef.current, resized)\n\n    }, 1000)\n  }\n\n  \n\n  return (\n    <div  className=\"app\">\n      <h1> AI FACE DETECTION</h1>\n      <div className='app__video'>\n        <video crossOrigin='anonymous' ref={videoRef} autoPlay ></video>\n      </div>\n        <canvas ref={canvasRef} width=\"940\" height=\"650\" className='app__canvas' />\n      \n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}