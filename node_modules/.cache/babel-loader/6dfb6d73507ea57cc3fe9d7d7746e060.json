{"ast":null,"code":"var _jsxFileName = \"/Users/abhinavprasad/Desktop/ai-face-detection/src/App.js\",\n    _s = $RefreshSig$();\n\nimport { useRef, useEffect } from 'react';\nimport './App.css';\nimport * as faceapi from \"face-api.js\";\nimport { FaceExpressions } from 'face-api.js'; // new faceapi.TinyFaceDetectorOptions()\n\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  const videoRef = useRef();\n  const canvasRef = useRef();\n  useEffect(() => {\n    startVideo();\n    videoRef && loadModels();\n  }, []);\n\n  const loadModels = () => {\n    Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri('/models'), faceapi.nets.faceLandmark68Net.loadFromUri('/models'), faceapi.nets.faceRecognitionNet.loadFromUri('/models'), faceapi.nets.faceExpressionNet.loadFromUri('/models')]).then(() => {\n      faceDetection();\n    });\n  };\n\n  const startVideo = () => {\n    navigator.mediaDevices.getUserMedia({\n      video: true\n    }).then(currentStream => {\n      videoRef.current.srcObject = currentStream;\n    }).catch(err => {\n      console.error(err);\n    });\n  };\n\n  const faceDetection = async () => {\n    setInterval(async () => {\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      let emotions_displayed = detections[0].expressions;\n      canvasRef.current.innerHtml = faceapi.createCanvasFromMedia(videoRef.current);\n      faceapi.matchDimensions(canvasRef.current, {\n        width: 940,\n        height: 650\n      });\n      const resized = faceapi.resizeResults(detections, {\n        width: 940,\n        height: 650\n      });\n      faceapi.draw.drawDetections(canvasRef.current, resized);\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, resized);\n      faceapi.draw.drawFaceExpressions(canvasRef.current, resized);\n    }, 1000);\n  };\n\n  let a = 5;\n  console.log(typeof a);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"app\",\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \" AI FACE DETECTION\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 67,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"  \"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 68,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"app__video\",\n      children: /*#__PURE__*/_jsxDEV(\"video\", {\n        crossOrigin: \"anonymous\",\n        ref: videoRef,\n        autoPlay: true\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 70,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 69,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      width: \"940\",\n      height: \"650\",\n      className: \"app__canvas\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 72,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 66,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"0gwqVvoOV2or9Ql4L8GH2BGn3hc=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/abhinavprasad/Desktop/ai-face-detection/src/App.js"],"names":["useRef","useEffect","faceapi","FaceExpressions","App","videoRef","canvasRef","startVideo","loadModels","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","faceDetection","navigator","mediaDevices","getUserMedia","video","currentStream","current","srcObject","catch","err","console","error","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","emotions_displayed","expressions","innerHtml","createCanvasFromMedia","matchDimensions","width","height","resized","resizeResults","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions","a","log"],"mappings":";;;AAAA,SAASA,MAAT,EAAiBC,SAAjB,QAAkC,OAAlC;AACA,OAAO,WAAP;AACA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;AACA,SAASC,eAAT,QAAgC,aAAhC,C,CACA;;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AACb,QAAMC,QAAQ,GAAGL,MAAM,EAAvB;AACA,QAAMM,SAAS,GAAGN,MAAM,EAAxB;AAEAC,EAAAA,SAAS,CAAC,MAAM;AACdM,IAAAA,UAAU;AAEVF,IAAAA,QAAQ,IAAIG,UAAU,EAAtB;AAED,GALQ,EAKN,EALM,CAAT;;AAOE,QAAMA,UAAU,GAAG,MAAM;AACvBC,IAAAA,OAAO,CAACC,GAAR,CAAY,CACVR,OAAO,CAACS,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0C,SAA1C,CADU,EAEVX,OAAO,CAACS,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2C,SAA3C,CAFU,EAGVX,OAAO,CAACS,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4C,SAA5C,CAHU,EAIVX,OAAO,CAACS,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2C,SAA3C,CAJU,CAAZ,EAKGI,IALH,CAKQ,MAAM;AACZC,MAAAA,aAAa;AACd,KAPD;AAQD,GATD;;AAWF,QAAMX,UAAU,GAAG,MAAM;AACvBY,IAAAA,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoC;AAAEC,MAAAA,KAAK,EAAE;AAAT,KAApC,EACGL,IADH,CACSM,aAAD,IAAmB;AACvBlB,MAAAA,QAAQ,CAACmB,OAAT,CAAiBC,SAAjB,GAA6BF,aAA7B;AACD,KAHH,EAIGG,KAJH,CAIUC,GAAD,IAAS;AACdC,MAAAA,OAAO,CAACC,KAAR,CAAcF,GAAd;AACD,KANH;AAOD,GARD;;AAUA,QAAMT,aAAa,GAAG,YAAY;AAChCY,IAAAA,WAAW,CAAC,YAAW;AACrB,YAAMC,UAAU,GAAG,MAAM7B,OAAO,CAAC8B,cAAR,CAAuB3B,QAAQ,CAACmB,OAAhC,EAAyC,IAAItB,OAAO,CAAC+B,uBAAZ,EAAzC,EAAgFC,iBAAhF,GAAoGC,mBAApG,EAAzB;AACA,UAAIC,kBAAkB,GAAGL,UAAU,CAAC,CAAD,CAAV,CAAcM,WAAvC;AAEA/B,MAAAA,SAAS,CAACkB,OAAV,CAAkBc,SAAlB,GAA8BpC,OAAO,CAACqC,qBAAR,CAA8BlC,QAAQ,CAACmB,OAAvC,CAA9B;AACAtB,MAAAA,OAAO,CAACsC,eAAR,CAAwBlC,SAAS,CAACkB,OAAlC,EAA2C;AACzCiB,QAAAA,KAAK,EAAE,GADkC;AAEzCC,QAAAA,MAAM,EAAE;AAFiC,OAA3C;AAKA,YAAMC,OAAO,GAAGzC,OAAO,CAAC0C,aAAR,CAAsBb,UAAtB,EAAkC;AAChDU,QAAAA,KAAK,EAAE,GADyC;AAEhDC,QAAAA,MAAM,EAAE;AAFwC,OAAlC,CAAhB;AAKAxC,MAAAA,OAAO,CAAC2C,IAAR,CAAaC,cAAb,CAA4BxC,SAAS,CAACkB,OAAtC,EAA+CmB,OAA/C;AACAzC,MAAAA,OAAO,CAAC2C,IAAR,CAAaE,iBAAb,CAA+BzC,SAAS,CAACkB,OAAzC,EAAkDmB,OAAlD;AACAzC,MAAAA,OAAO,CAAC2C,IAAR,CAAaG,mBAAb,CAAiC1C,SAAS,CAACkB,OAA3C,EAAoDmB,OAApD;AAED,KAnBU,EAmBR,IAnBQ,CAAX;AAoBD,GArBD;;AAuBA,MAAIM,CAAC,GAAG,CAAR;AACArB,EAAAA,OAAO,CAACsB,GAAR,CAAY,OAAOD,CAAnB;AAEA,sBACE;AAAM,IAAA,SAAS,EAAC,KAAhB;AAAA,4BACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF,eAGE;AAAK,MAAA,SAAS,EAAC,YAAf;AAAA,6BACE;AAAO,QAAA,WAAW,EAAC,WAAnB;AAA+B,QAAA,GAAG,EAAE5C,QAApC;AAA8C,QAAA,QAAQ;AAAtD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,YAHF,eAMI;AAAQ,MAAA,GAAG,EAAEC,SAAb;AAAwB,MAAA,KAAK,EAAC,KAA9B;AAAoC,MAAA,MAAM,EAAC,KAA3C;AAAiD,MAAA,SAAS,EAAC;AAA3D;AAAA;AAAA;AAAA;AAAA,YANJ;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAWD;;GArEQF,G;;KAAAA,G;AAuET,eAAeA,GAAf","sourcesContent":["import { useRef, useEffect } from 'react';\nimport './App.css';\nimport * as faceapi from \"face-api.js\";\nimport { FaceExpressions } from 'face-api.js';\n// new faceapi.TinyFaceDetectorOptions()\n\nfunction App() {\n  const videoRef = useRef();\n  const canvasRef = useRef();\n\n  useEffect(() => {\n    startVideo();\n\n    videoRef && loadModels();\n\n  }, []);\n  \n    const loadModels = () => {\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri('/models'),\n        faceapi.nets.faceLandmark68Net.loadFromUri('/models'),\n        faceapi.nets.faceRecognitionNet.loadFromUri('/models'),\n        faceapi.nets.faceExpressionNet.loadFromUri('/models'),\n      ]).then(() => {\n        faceDetection();\n      })\n    };\n\n  const startVideo = () => {\n    navigator.mediaDevices.getUserMedia({ video: true })\n      .then((currentStream) => {\n        videoRef.current.srcObject = currentStream;\n      })\n      .catch((err) => {\n        console.error(err)\n      });\n  }\n\n  const faceDetection = async () => {\n    setInterval(async() => {\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      let emotions_displayed = detections[0].expressions;\n      \n      canvasRef.current.innerHtml = faceapi.createCanvasFromMedia(videoRef.current);\n      faceapi.matchDimensions(canvasRef.current, {\n        width: 940,\n        height: 650,\n      })\n\n      const resized = faceapi.resizeResults(detections, {\n        width: 940,\n        height: 650,\n      });\n\n      faceapi.draw.drawDetections(canvasRef.current, resized)\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, resized)\n      faceapi.draw.drawFaceExpressions(canvasRef.current, resized)\n\n    }, 1000)\n  }\n  \n  let a = 5\n  console.log(typeof(a))\n\n  return (\n    <div  className=\"app\">\n      <h1> AI FACE DETECTION</h1>\n      <h1>  </h1>\n      <div className='app__video'>\n        <video crossOrigin='anonymous' ref={videoRef} autoPlay ></video>\n      </div>\n        <canvas ref={canvasRef} width=\"940\" height=\"650\" className='app__canvas' />\n      \n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}